[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tips & tRicks in R",
    "section": "",
    "text": "This website contains the living documentation of R Tips & tRicks."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a resource created from markdown and executable code. The github repo containing all of the code can be found here. These are pieces of code that I regularly use in my work and have created this site to create one cohesive location to easily search and find relevant code."
  },
  {
    "objectID": "data-exploration.html",
    "href": "data-exploration.html",
    "title": "Data Exploration",
    "section": "",
    "text": "We want to show you the “whole game” of data science giving you just enough of all the major pieces so that you can tackle real, if simple, data sets. The later parts of the book, will hit each of these topics in more depth, increasing the range of data science challenges that you can tackle.\nFive chapters focus on the tools of data science:\n\nVisualisation is a great place to start with R programming, because the payoff is so clear: you get to make elegant and informative plots that help you understand data. In … you’ll dive into visualization, learning the basic structure of a ggplot2 plot, and powerful techniques for turning data into plots.\nVisualisation alone is typically not enough, so in Chapter 2, you’ll learn the key verbs that allow you to select important variables, filter out key observations, create new variables, and compute summaries.\nIn Chapter 3, you’ll learn about tidy data, a consistent way of storing your data that makes transformation, visualization, and modelling easier. You’ll learn the underlying principles, and how to get your data into a tidy form."
  },
  {
    "objectID": "psych.html",
    "href": "psych.html",
    "title": "2  The psych package",
    "section": "",
    "text": "In this chapter, I will focus exclusively on the psych package. I will cover all of the functions that I regularly use.\n\nIf you do not already have the psych package downloaded, you will first need to run install.packages(\"psych\")\nThen, you will be able to load the library and use its functions.\n\nlibrary(psych)\n\nWe will be using the bfi dataset that is included in the psych package. It is described as follows: 25 personality self report items taken from the International Personality Item Pool (ipip.ori.org) were included as part of the Synthetic Aperture Personality Assessment (SAPA) web based personality assessment project. The data from 2800 subjects are included here as a demonstration set for scale construction, factor analysis, and Item Response Theory analysis. Three additional demographic variables (sex, education, and age) are also included.\n\ndata(bfi)"
  },
  {
    "objectID": "psych.html#sec-describe",
    "href": "psych.html#sec-describe",
    "title": "2  The psych package",
    "section": "\n2.2 Describing Data",
    "text": "2.2 Describing Data\nThe describe() function will return the following for any numeric variable: number of valid cases, mean, standard deviation, trimmed mean (with trim defaulting to .1) , median (standard or interpolated, mad: median absolute deviation (from the median), minimum, maximum, skew, kurtosis, standard error.\nBelow I am describing the A2 variable which has responses to the Agreeableness statement: Inquire about others' well-being.\n\ndescribe(bfi$A2)\n\n   vars    n mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 2773  4.8 1.17      5    4.98 1.48   1   6     5 -1.12     1.05 0.02\n\n\nYou can also describe by groups which will return descriptive statistics by groups. Below I am describing the A2 variable by gender. Males = 1, Females =2.\n\ndescribeBy(A2 ~ gender, data = bfi)\n\n\n Descriptive statistics by group \ngender: 1\n   vars   n mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 908  4.5 1.26      5    4.65 1.48   1   6     5 -0.89     0.34 0.04\n------------------------------------------------------------ \ngender: 2\n   vars    n mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 1865 4.95 1.09      5    5.12 1.48   1   6     5 -1.24     1.55 0.03\n\n\nAnother useful function is headTail which will show the first and last couple of lines of a dataset.\n\nheadTail(bfi)\n\n       A1  A2  A3  A4  A5  C1  C2  C3  C4  C5  E1  E2  E3  E4  E5   N1  N2  N3\n61617   2   4   3   4   4   2   3   3   4   4   3   3   3   4   4    3   4   2\n61618   2   4   5   2   5   5   4   4   3   4   1   1   6   4   3    3   3   3\n61620   5   4   5   4   4   4   5   4   2   5   2   4   4   4   5    4   5   4\n61621   4   4   6   5   5   4   4   3   5   5   5   3   4   4   4    2   5   2\n...   ... ... ... ... ... ... ... ... ... ... ... ... ... ... ...  ... ... ...\n67552   2   4   4   3   5   2   3   4   4   3   2   2   4   4   3 <NA>   3   2\n67556   2   3   5   2   5   5   5   5   1   1   2   2   6   3   6    3   4   3\n67559   5   2   2   4   4   5   5   5   2   6   2   2   4   5   4    5   5   6\n67560   2   3   1   4   2   5   5   3   3   3   3   3   1   2   2    1   2   2\n       N4  N5  O1  O2  O3  O4  O5 gender education age\n61617   2   3   3   6   3   4   3      1      <NA>  16\n61618   5   5   4   2   4   3   3      2      <NA>  18\n61620   2   3   4   2   5   5   2      2      <NA>  17\n61621   4   1   3   3   4   3   5      2      <NA>  17\n...   ... ... ... ... ... ... ...    ...       ... ...\n67552   3   3   6   3   5   4   2      1         4  27\n67556   3   1   5   1   6   4   3      2         4  29\n67559   4   1   5   2   5   5   1      1         4  31\n67560   1   1   3   1   3   5   1      2         4  50"
  },
  {
    "objectID": "tidyverse.html",
    "href": "tidyverse.html",
    "title": "3  The tidyverse",
    "section": "",
    "text": "“Happy families are all alike; every unhappy family is unhappy in its own way.”\n— Leo Tolstoy\n\n\n“Tidy datasets are all alike, but every messy dataset is messy in its own way.”\n— Hadley Wickham\n\nIn this chapter, you will learn a consistent way to organize your data in R using a system called tidy data. Getting your data into this format requires some work up front, but that work pays off in the long term. Once you have tidy data and the tidy tools provided by packages in the tidyverse, you will spend much less time munging data from one representation to another, allowing you to spend more time on the data questions you care about.\nIn this chapter, you’ll first learn the definition of tidy data and see it applied to simple toy dataset. Then we’ll dive into the main tool you’ll use for tidying data: pivoting. Pivoting allows you to change the form of your data, without changing any of the values. We’ll finish up with a discussion of usefully untidy data, and how you can create it if needed.\n\nIn this chapter we’ll focus on tidyr, a package that provides a bunch of tools to help tidy up your messy datasets. tidyr is a member of the core tidyverse.\n\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.1.2\n\n\nWarning: package 'readr' was built under R version 4.1.2\n\n\nFrom this chapter on, we’ll suppress the loading message from library(tidyverse)."
  },
  {
    "objectID": "tidyverse.html#sec-tidy-data",
    "href": "tidyverse.html#sec-tidy-data",
    "title": "3  The tidyverse",
    "section": "\n3.2 Tidy data",
    "text": "3.2 Tidy data\nYou can represent the same underlying data in multiple ways. The example below shows the same data organised in four different ways. Each dataset shows the same values of four variables: country, year, population, and cases of TB (tuberculosis), but each dataset organizes the values in a different way.\n\n\n\ntable1\n\n# A tibble: 6 × 4\n  country      year  cases population\n  <chr>       <int>  <int>      <int>\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\ntable2\n\n# A tibble: 12 × 4\n   country      year type            count\n   <chr>       <int> <chr>           <int>\n 1 Afghanistan  1999 cases             745\n 2 Afghanistan  1999 population   19987071\n 3 Afghanistan  2000 cases            2666\n 4 Afghanistan  2000 population   20595360\n 5 Brazil       1999 cases           37737\n 6 Brazil       1999 population  172006362\n 7 Brazil       2000 cases           80488\n 8 Brazil       2000 population  174504898\n 9 China        1999 cases          212258\n10 China        1999 population 1272915272\n11 China        2000 cases          213766\n12 China        2000 population 1280428583\n\ntable3\n\n# A tibble: 6 × 3\n  country      year rate             \n* <chr>       <int> <chr>            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583\n\n# Spread across two tibbles\ntable4a # cases\n\n# A tibble: 3 × 3\n  country     `1999` `2000`\n* <chr>        <int>  <int>\n1 Afghanistan    745   2666\n2 Brazil       37737  80488\n3 China       212258 213766\n\ntable4b # population\n\n# A tibble: 3 × 3\n  country         `1999`     `2000`\n* <chr>            <int>      <int>\n1 Afghanistan   19987071   20595360\n2 Brazil       172006362  174504898\n3 China       1272915272 1280428583\n\n\nThese are all representations of the same underlying data, but they are not equally easy to use. One of them, table1, will be much easier to work with inside the tidyverse because it’s tidy.\nThere are three interrelated rules that make a dataset tidy:\n\nEach variable is a column; each column is a variable.\nEach observation is row; each row is an observation.\nEach value is a cell; each cell is a single value.\n\n?fig-tidy-structure shows the rules visually.\nWhy ensure that your data is tidy? There are two main advantages:\n\nThere’s a general advantage to picking one consistent way of storing data. If you have a consistent data structure, it’s easier to learn the tools that work with it because they have an underlying uniformity.\nThere’s a specific advantage to placing variables in columns because it allows R’s vectorised nature to shine. As you learned in ?sec-mutate and ?sec-summarize, most built-in R functions work with vectors of values. That makes transforming tidy data feel particularly natural.\n\ndplyr, ggplot2, and all the other packages in the tidyverse are designed to work with tidy data. Here are a couple of small examples showing how you might work with table1.\n\n# Compute rate per 10,000\ntable1 |>\n  mutate(\n    rate = cases / population * 10000\n  )\n\n# A tibble: 6 × 5\n  country      year  cases population  rate\n  <chr>       <int>  <int>      <int> <dbl>\n1 Afghanistan  1999    745   19987071 0.373\n2 Afghanistan  2000   2666   20595360 1.29 \n3 Brazil       1999  37737  172006362 2.19 \n4 Brazil       2000  80488  174504898 4.61 \n5 China        1999 212258 1272915272 1.67 \n6 China        2000 213766 1280428583 1.67 \n\n# Compute cases per year\ntable1 |>\n  count(year, wt = cases)\n\n# A tibble: 2 × 2\n   year      n\n  <int>  <int>\n1  1999 250740\n2  2000 296920\n\n# Visualise changes over time\nggplot(table1, aes(year, cases)) +\n  geom_line(aes(group = country), color = \"grey50\") +\n  geom_point(aes(color = country, shape = country)) +\n  scale_x_continuous(breaks = c(1999, 2000))\n\n\n\n\n\n3.2.1 Exercises\n\nUsing prose, describe how the variables and observations are organised in each of the sample tables.\n\nSketch out the process you’d use to calculate the rate for table2 and table4a + table4b. You will need to perform four operations:\n\nExtract the number of TB cases per country per year.\nExtract the matching population per country per year.\nDivide cases by population, and multiply by 10000.\nStore back in the appropriate place.\n\nYou haven’t yet learned all the functions you’d need to actually perform these operations, but you should still be able to think through the transformations you’d need.\n\nRecreate the plot showing change in cases over time using table2 instead of table1. What do you need to do first?"
  },
  {
    "objectID": "tidyverse.html#pivoting",
    "href": "tidyverse.html#pivoting",
    "title": "3  The tidyverse",
    "section": "\n3.3 Pivoting",
    "text": "3.3 Pivoting\nThe principles of tidy data might seem so obvious that you wonder if you’ll ever encounter a dataset that isn’t tidy. Unfortunately, however, most real data is untidy. There are two main reasons:\n\nData is often organised to facilitate some goal other than analysis. For example, it’s common for data to be structured to make data entry, not analysis, easy.\nMost people aren’t familiar with the principles of tidy data, and it’s hard to derive them yourself unless you spend a lot of time working with data.\n\nThis means that most real analyses will require at least a little tidying. You’ll begin by figuring out what the underlying variables and observations are. Sometimes this is easy; other times you’ll need to consult with the people who originally generated the data. Next, you’ll pivot your data into a tidy form, with variables in the columns and observations in the rows.\ntidyr provides two functions for pivoting data: pivot_longer(), which makes datasets longer by increasing rows and reducing columns, and pivot_wider() which makes datasets wider by increasing columns and reducing rows. The following sections work through the use of pivot_longer() and pivot_wider() to tackle a wide range of realistic datasets. These examples are drawn from vignette(\"pivot\", package = \"tidyr\"), which you should check out if you want to see more variations and more challenging problems.\nLet’s dive in.\n\n3.3.1 Data in column names\nThe billboard dataset records the billboard rank of songs in the year 2000:\n\nbillboard\n\n# A tibble: 317 × 79\n   artist   track   date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8\n   <chr>    <chr>   <date>       <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 2 Pac    Baby D… 2000-02-26      87    82    72    77    87    94    99    NA\n 2 2Ge+her  The Ha… 2000-09-02      91    87    92    NA    NA    NA    NA    NA\n 3 3 Doors… Krypto… 2000-04-08      81    70    68    67    66    57    54    53\n 4 3 Doors… Loser   2000-10-21      76    76    72    69    67    65    55    59\n 5 504 Boyz Wobble… 2000-04-15      57    34    25    17    17    31    36    49\n 6 98^0     Give M… 2000-08-19      51    39    34    26    26    19     2     2\n 7 A*Teens  Dancin… 2000-07-08      97    97    96    95   100    NA    NA    NA\n 8 Aaliyah  I Don'… 2000-01-29      84    62    51    41    38    35    35    38\n 9 Aaliyah  Try Ag… 2000-03-18      59    53    38    28    21    18    16    14\n10 Adams, … Open M… 2000-08-26      76    76    74    69    68    67    61    58\n# … with 307 more rows, and 68 more variables: wk9 <dbl>, wk10 <dbl>,\n#   wk11 <dbl>, wk12 <dbl>, wk13 <dbl>, wk14 <dbl>, wk15 <dbl>, wk16 <dbl>,\n#   wk17 <dbl>, wk18 <dbl>, wk19 <dbl>, wk20 <dbl>, wk21 <dbl>, wk22 <dbl>,\n#   wk23 <dbl>, wk24 <dbl>, wk25 <dbl>, wk26 <dbl>, wk27 <dbl>, wk28 <dbl>,\n#   wk29 <dbl>, wk30 <dbl>, wk31 <dbl>, wk32 <dbl>, wk33 <dbl>, wk34 <dbl>,\n#   wk35 <dbl>, wk36 <dbl>, wk37 <dbl>, wk38 <dbl>, wk39 <dbl>, wk40 <dbl>,\n#   wk41 <dbl>, wk42 <dbl>, wk43 <dbl>, wk44 <dbl>, wk45 <dbl>, wk46 <dbl>, …\n\n\nIn this dataset, each observation is a song. The first three columns (artist, track and date.entered) are variables that describe the song. Then we have 76 columns (wk1-wk76) that describe the rank of the song in each week. Here, the column names are one variable (the week) and the cell values are another (the rank).\nTo tidy this data, we’ll use pivot_longer(). After the data, there are three key arguments:\n\n\ncols specifies which columns need to be pivoted, i.e. which columns aren’t variables. This argument uses the same syntax as select() so here we could use !c(artist, track, date.entered) or starts_with(\"wk\").\n\nnames_to names of the variable stored in the column names, here \"week\".\n\nvalues_to names the variable stored in the cell values, here \"rank\".\n\nThat gives the following call:\n\nbillboard |> \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\"\n  )\n\n# A tibble: 24,092 × 5\n   artist track                   date.entered week   rank\n   <chr>  <chr>                   <date>       <chr> <dbl>\n 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87\n 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82\n 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72\n 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77\n 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87\n 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94\n 7 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk7      99\n 8 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk8      NA\n 9 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk9      NA\n10 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk10     NA\n# … with 24,082 more rows\n\n\nWhat happens if a song is in the top 100 for less than 76 weeks? Take 2 Pac’s “Baby Don’t Cry”, for example. The above output suggests that it was only the top 100 for 7 weeks, and all the remaining weeks are filled in with missing values. These NAs don’t really represent unknown observations; they’re forced to exist by the structure of the dataset1, so we can ask pivot_longer() to get rid of them by setting values_drop_na = TRUE:\n\nbillboard |> \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\",\n    values_drop_na = TRUE\n  )\n\n# A tibble: 5,307 × 5\n   artist  track                   date.entered week   rank\n   <chr>   <chr>                   <date>       <chr> <dbl>\n 1 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk1      87\n 2 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk2      82\n 3 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk3      72\n 4 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk4      77\n 5 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk5      87\n 6 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk6      94\n 7 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk7      99\n 8 2Ge+her The Hardest Part Of ... 2000-09-02   wk1      91\n 9 2Ge+her The Hardest Part Of ... 2000-09-02   wk2      87\n10 2Ge+her The Hardest Part Of ... 2000-09-02   wk3      92\n# … with 5,297 more rows\n\n\nYou might also wonder what happens if a song is in the top 100 for more than 76 weeks? We can’t tell from this data, but you might guess that additional columns wk77, wk78, … would be added to the dataset.\nThis data is now tidy, but we could make future computation a bit easier by converting week into a number using mutate() and parse_number(). You’ll learn more about parse_number() and friends in ?sec-data-import.\n\nbillboard_tidy <- billboard |> \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\",\n    values_drop_na = TRUE\n  ) |> \n  mutate(\n    week = parse_number(week)\n  )\nbillboard_tidy\n\n# A tibble: 5,307 × 5\n   artist  track                   date.entered  week  rank\n   <chr>   <chr>                   <date>       <dbl> <dbl>\n 1 2 Pac   Baby Don't Cry (Keep... 2000-02-26       1    87\n 2 2 Pac   Baby Don't Cry (Keep... 2000-02-26       2    82\n 3 2 Pac   Baby Don't Cry (Keep... 2000-02-26       3    72\n 4 2 Pac   Baby Don't Cry (Keep... 2000-02-26       4    77\n 5 2 Pac   Baby Don't Cry (Keep... 2000-02-26       5    87\n 6 2 Pac   Baby Don't Cry (Keep... 2000-02-26       6    94\n 7 2 Pac   Baby Don't Cry (Keep... 2000-02-26       7    99\n 8 2Ge+her The Hardest Part Of ... 2000-09-02       1    91\n 9 2Ge+her The Hardest Part Of ... 2000-09-02       2    87\n10 2Ge+her The Hardest Part Of ... 2000-09-02       3    92\n# … with 5,297 more rows\n\n\nNow we’re in a good position to look at how song ranks vary over time by drawing a plot. The code is shown below and the result is Figure 3.1.\n\nbillboard_tidy |> \n  ggplot(aes(week, rank, group = track)) + \n  geom_line(alpha = 1/3) + \n  scale_y_reverse()\n\n\n\nFigure 3.1: A line plot showing how the rank of a song changes over time.\n\n\n\n\n\n3.3.2 How does pivoting work?\nNow that you’ve seen what pivoting can do for you, it’s worth taking a little time to gain some intuition about what it does to the data. Let’s start with a very simple dataset to make it easier to see what’s happening:\n\ndf <- tribble(\n  ~var, ~col1, ~col2,\n   \"A\",     1,     2,\n   \"B\",     3,     4,\n   \"C\",     5,     6\n)\n\nHere we’ll say there are three variables: var (already in a variable), name (the column names in the column names), and value (the cell values). So we can tidy it with:\n\ndf |> \n  pivot_longer(\n    cols = col1:col2,\n    names_to = \"names\",\n    values_to = \"values\"\n  )\n\n# A tibble: 6 × 3\n  var   names values\n  <chr> <chr>  <dbl>\n1 A     col1       1\n2 A     col2       2\n3 B     col1       3\n4 B     col2       4\n5 C     col1       5\n6 C     col2       6\n\n\nHow does this transformation take place? It’s easier to see if we take it component by component. Columns that are already variables need to be repeated, once for each column in cols, as shown in ?fig-pivot-variables.\nThe column names become values in a new variable, whose name is given by names_to, as shown in ?fig-pivot-names. They need to be repeated once for each row in the original dataset.\nThe cell values also become values in a new variable, with a name given by values_to. They are unwound row by row. ?fig-pivot-values illustrates the process.\n\n3.3.3 Many variables in column names\nA more challenging situation occurs when you have multiple variables crammed into the column names. For example, take the who2 dataset:\nThis dataset records information about tuberculosis data collected by the WHO. There are two columns that are already variables and are easy to interpret: country and year. They are followed by 56 columns like sp_m_014, ep_m_4554, and rel_m_3544. If you stare at these columns for long enough, you’ll notice there’s a pattern. Each column name is made up of three pieces separated by _. The first piece, sp/rel/ep, describes the method used for the diagnosis, the second piece, m/f is the gender, and the third piece, 014/1524/2535/3544/4554/65 is the age range.\nSo in this case we have six variables: two variables are already columns, three variables are contained in the column name, and one variable is in the cell name. This requires two changes to our call to pivot_longer(): names_to gets a vector of column names and names_sep describes how to split the variable name up into pieces:\nOf course, tidy data can’t solve every problem so we also showed you some places were you might want to deliberately untidy your data into order to present to humans, feed into statistical models, or just pragmatically get shit done. If you particularly enjoyed this chapter and want to learn more about the underlying theory, you can learn more about the history and theoretical underpinnings in the Tidy Data paper published in the Journal of Statistical Software.\nIn the next chapter, we’ll pivot back to workflow to discuss the importance of code style, keeping your code “tidy” (ha!) in order to make it easy for you and others to read and understand your code."
  }
]